{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is it? \uf0c1 clu-phontools is a collection of tools for phonological analysis. What does it support? \uf0c1 phonological sequence alignment pronunciation generation (EN) feature-based phonological comparisons How do I use it? \uf0c1 See our examples .","title":"Home"},{"location":"#what-is-it","text":"clu-phontools is a collection of tools for phonological analysis.","title":"What is it?"},{"location":"#what-does-it-support","text":"phonological sequence alignment pronunciation generation (EN) feature-based phonological comparisons","title":"What does it support?"},{"location":"#how-do-i-use-it","text":"See our examples .","title":"How do I use it?"},{"location":"contributing/","text":"","title":"Contributing"},{"location":"install/","text":"Installation \uf0c1 clu-phontools can be run one of two ways: Local installation of Python library (>= v3.8) Using Docker Python \uf0c1 Requirements \uf0c1 Python (>= v3.8) Install \uf0c1 To install directly from the default branch of the repository: pip install git+https://github.com/clu-ling/clu-phontools.git Docker \uf0c1 Requirements \uf0c1 Docker Install \uf0c1 Docker images are periodically published to DockerHub : docker pull \"parsertongue/clu-phontools:latest\"","title":"Installation"},{"location":"install/#installation","text":"clu-phontools can be run one of two ways: Local installation of Python library (>= v3.8) Using Docker","title":"Installation"},{"location":"install/#python","text":"","title":"Python"},{"location":"install/#requirements","text":"Python (>= v3.8)","title":"Requirements"},{"location":"install/#install","text":"To install directly from the default branch of the repository: pip install git+https://github.com/clu-ling/clu-phontools.git","title":"Install"},{"location":"install/#docker","text":"","title":"Docker"},{"location":"install/#requirements_1","text":"Docker","title":"Requirements"},{"location":"install/#install_1","text":"Docker images are periodically published to DockerHub : docker pull \"parsertongue/clu-phontools:latest\"","title":"Install"},{"location":"tutorial/","text":"Run RE-ALINE against Excel data \uf0c1 mkdir {input,output} Move your Excel input data into input/ as input.xlsx and run the following command: docker run -it --rm \"parsertongue/re-aline:latest\" re-aline-excel-data --input /app/input.xlsx --output /app/output.xlsx","title":"Usage"},{"location":"tutorial/#run-re-aline-against-excel-data","text":"mkdir {input,output} Move your Excel input data into input/ as input.xlsx and run the following command: docker run -it --rm \"parsertongue/re-aline:latest\" re-aline-excel-data --input /app/input.xlsx --output /app/output.xlsx","title":"Run RE-ALINE against Excel data"},{"location":"dev/documentation/","text":"Documentation \uf0c1 API documentation \uf0c1 We use pdoc to generate our API documentation. To develop with live reloading, use the following command: LaTeX math in docstrings To use LaTeX-style equations, we recommend using raw strings for docstrings: r\"\"\"My docstring Thanks to the r prefix, we can write math without needing to escape \\: $$\\sum_{i=1}^{\\vert X \\vert} x_{i}$$ \"\"\" Docker \uf0c1 # execute the following command from the project root: docker run --rm -it -v $PWD:/app \\ -p 8001:8001 \\ parsertongue/clu-phontools:latest \\ pdoc --html -c latex_math=True --force --output-dir docs/api --http 0.0.0.0:8001 clu Open your browser to localhost:8001/clu/phontools to see live updates. Anaconda \uf0c1 source activate clu-phontools # execute the following command from the project root: pdoc --html -c latex_math=True --force --output-dir docs/api --http 0.0.0.0:8001 clu Open your browser to localhost:8001/clu/phontools to see live updates. General documentation \uf0c1 We use mkdocs to generate our site documentation from markdown. Markdown source files are located udner the docs directory. Docker \uf0c1 # execute the following command from the project root: docker run --rm -it -v $PWD:/app \\ -p 8000:8000 \\ parsertongue/clu-phontools:latest \\ mkdocs serve -a 0.0.0.0:8000 Open your browser to localhost:8000 to see live updates. Anaconda \uf0c1 To develop the documentation with live reloading, run the following command: source activate clu-phontools # execute the following command from the project root: mkdocs serve -a 0.0.0.0:8000 Open your browser to localhost:8000 to see live updates.","title":"Documentation"},{"location":"dev/documentation/#documentation","text":"","title":"Documentation"},{"location":"dev/documentation/#api-documentation","text":"We use pdoc to generate our API documentation. To develop with live reloading, use the following command: LaTeX math in docstrings To use LaTeX-style equations, we recommend using raw strings for docstrings: r\"\"\"My docstring Thanks to the r prefix, we can write math without needing to escape \\: $$\\sum_{i=1}^{\\vert X \\vert} x_{i}$$ \"\"\"","title":"API documentation"},{"location":"dev/documentation/#docker","text":"# execute the following command from the project root: docker run --rm -it -v $PWD:/app \\ -p 8001:8001 \\ parsertongue/clu-phontools:latest \\ pdoc --html -c latex_math=True --force --output-dir docs/api --http 0.0.0.0:8001 clu Open your browser to localhost:8001/clu/phontools to see live updates.","title":"Docker"},{"location":"dev/documentation/#anaconda","text":"source activate clu-phontools # execute the following command from the project root: pdoc --html -c latex_math=True --force --output-dir docs/api --http 0.0.0.0:8001 clu Open your browser to localhost:8001/clu/phontools to see live updates.","title":"Anaconda"},{"location":"dev/documentation/#general-documentation","text":"We use mkdocs to generate our site documentation from markdown. Markdown source files are located udner the docs directory.","title":"General documentation"},{"location":"dev/documentation/#docker_1","text":"# execute the following command from the project root: docker run --rm -it -v $PWD:/app \\ -p 8000:8000 \\ parsertongue/clu-phontools:latest \\ mkdocs serve -a 0.0.0.0:8000 Open your browser to localhost:8000 to see live updates.","title":"Docker"},{"location":"dev/documentation/#anaconda_1","text":"To develop the documentation with live reloading, run the following command: source activate clu-phontools # execute the following command from the project root: mkdocs serve -a 0.0.0.0:8000 Open your browser to localhost:8000 to see live updates.","title":"Anaconda"},{"location":"dev/formatting/","text":"Formatting and style \uf0c1 Code can be auto-formatted using black : Docker \uf0c1 docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" black Anaconda \uf0c1 source activate clu-phontools # execute the following command from the project root: black Typehints \uf0c1 The code makes use of Python type hints. Docker \uf0c1 To perform type checking, run the following command: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" mypy --ignore-missing-imports --follow-imports=skip --strict-optional . Anaconda \uf0c1 source activate clu-phontools # execute the following command from the project root: mypy --ignore-missing-imports --follow-imports=skip --strict-optional .","title":"Formatting"},{"location":"dev/formatting/#formatting-and-style","text":"Code can be auto-formatted using black :","title":"Formatting and style"},{"location":"dev/formatting/#docker","text":"docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" black","title":"Docker"},{"location":"dev/formatting/#anaconda","text":"source activate clu-phontools # execute the following command from the project root: black","title":"Anaconda"},{"location":"dev/formatting/#typehints","text":"The code makes use of Python type hints.","title":"Typehints"},{"location":"dev/formatting/#docker_1","text":"To perform type checking, run the following command: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" mypy --ignore-missing-imports --follow-imports=skip --strict-optional .","title":"Docker"},{"location":"dev/formatting/#anaconda_1","text":"source activate clu-phontools # execute the following command from the project root: mypy --ignore-missing-imports --follow-imports=skip --strict-optional .","title":"Anaconda"},{"location":"dev/install/","text":"Installation \uf0c1 Anaconda \uf0c1 clu-phontools is written for Python >= v3.8 . One option for development is to install the library in a virtual environment (ex. conda , venv , poetry , etc.). Using conda , the library can be installed interactively in an isolated environment using the following commands: conda create --name clu-phontools python=3.8 ipython source activate clu-phontools # execute the following command from the project root: pip install -e \".[dev]\" [dev] will include dependencies for running tests and generating the documentation. Docker \uf0c1 For those familiar with Docker, another option is to use a container with bind mounts as a development environment. Note that the instructions below assume you're developing using a Linux-based environment (they've also been tested on MacOS Catalina). First, you'll need to build the docker image: docker build -f Dockerfile -t \"parsertongue/clu-phontools:latest\" . Launch a container using this image and connect to it: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest /bin/bash\" Thanks to the bind mount, changes made to files locally (i.e., outside of the container) will be reflected inside the running container. The parsertongue/clu-phontools includes Jupyter and iPython: ipython from clu.phontools import ReAline realigner = ReAline() Removing old docker containers, images, etc. \uf0c1 If you want to save some space on your machine by removing images and containers you're no longer using, see the instructions here . As always, use caution when deleting things.","title":"Install"},{"location":"dev/install/#installation","text":"","title":"Installation"},{"location":"dev/install/#anaconda","text":"clu-phontools is written for Python >= v3.8 . One option for development is to install the library in a virtual environment (ex. conda , venv , poetry , etc.). Using conda , the library can be installed interactively in an isolated environment using the following commands: conda create --name clu-phontools python=3.8 ipython source activate clu-phontools # execute the following command from the project root: pip install -e \".[dev]\" [dev] will include dependencies for running tests and generating the documentation.","title":"Anaconda"},{"location":"dev/install/#docker","text":"For those familiar with Docker, another option is to use a container with bind mounts as a development environment. Note that the instructions below assume you're developing using a Linux-based environment (they've also been tested on MacOS Catalina). First, you'll need to build the docker image: docker build -f Dockerfile -t \"parsertongue/clu-phontools:latest\" . Launch a container using this image and connect to it: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest /bin/bash\" Thanks to the bind mount, changes made to files locally (i.e., outside of the container) will be reflected inside the running container. The parsertongue/clu-phontools includes Jupyter and iPython: ipython from clu.phontools import ReAline realigner = ReAline()","title":"Docker"},{"location":"dev/install/#removing-old-docker-containers-images-etc","text":"If you want to save some space on your machine by removing images and containers you're no longer using, see the instructions here . As always, use caution when deleting things.","title":"Removing old docker containers, images, etc."},{"location":"dev/test/","text":"Testing \uf0c1 Tests are written by extending the TestCase class from the unittest module in the Python standard library. All tests can be found in the tests directory. Docker \uf0c1 All tests can be run using the following command: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" test-all To run just the unit tests (with code coverage), run the following command: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" green -vvv --run-coverage Anaconda \uf0c1 source activate clu-phontools # execute the following command from the project root: green -vvv . Typehints \uf0c1 The code makes use of Python type hints. Docker \uf0c1 To perform type checking, run the following command: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" mypy --ignore-missing-imports --follow-imports=skip --strict-optional . Anaconda \uf0c1 source activate clu-phontools # execute the following command from the project root: mypy --ignore-missing-imports --follow-imports=skip --strict-optional .","title":"Testing"},{"location":"dev/test/#testing","text":"Tests are written by extending the TestCase class from the unittest module in the Python standard library. All tests can be found in the tests directory.","title":"Testing"},{"location":"dev/test/#docker","text":"All tests can be run using the following command: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" test-all To run just the unit tests (with code coverage), run the following command: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" green -vvv --run-coverage","title":"Docker"},{"location":"dev/test/#anaconda","text":"source activate clu-phontools # execute the following command from the project root: green -vvv .","title":"Anaconda"},{"location":"dev/test/#typehints","text":"The code makes use of Python type hints.","title":"Typehints"},{"location":"dev/test/#docker_1","text":"To perform type checking, run the following command: docker run -it -v $PWD:/app \"parsertongue/clu-phontools:latest\" mypy --ignore-missing-imports --follow-imports=skip --strict-optional .","title":"Docker"},{"location":"dev/test/#anaconda_1","text":"source activate clu-phontools # execute the following command from the project root: mypy --ignore-missing-imports --follow-imports=skip --strict-optional .","title":"Anaconda"},{"location":"examples/asu-use-case/","text":"Introduction \uf0c1 Let's take a look at how to use ReAline to align phonological sequences and then analyze errors in the style of Jiao et al. (2019) For this example, we'll need the following imports: from clu.phontools.lang.en import EnglishUtils from clu.phontools.struct import * from clu.phontools.pronouncing import ConverterUtils from clu.phontools.alignment.realine import * from clu.phontools.alignment.lbe import * We'll be aligning a target phrase with a transcript phrase. In our example, our target phrase will be ... balance clamp and bottle ... and our transcribed phrase will be ... bell is glad a bottle Phrases and syllables \uf0c1 clu-phontools makes it easy to find all possible attested pronunciations for a phrase via a pronouncing dictionary. In the case of English, we can use the CMU pronouncing dictionary : # prompt/target is \"balance clamp and bottle\" # get all pronunciations for the phrase # return a sequence of `clu.phontools.struct.Phrase` target_phrases = EnglishUtils.all_possible_phrases_for([\"balance\", \"clamp\", \"and\", \"bottle\"]) How many pronunciations did we find? In this case, there should be 2: assert len(target_phrases) == 2 Let's examine the stress patterns . Perhaps we only care about the distinction between strong (S) and weak (W) syllables: # let's examine the stress patterns... for phrase in target_phrases: print(phrase.coarse_stress) Perhaps we have a particular stress pattern we're interested in examining. For this example, we'll pretend we're interested in finding phrases with the stres pattern SW S W SW : # our stress pattern of interest pattern = \"SW S W SW\" # find the first Phrase that matches our pattern. # we'll use the first entry (stress pattern = [\"SW\", \"S\", \"W\", \"SW\"]) # as our target. match_stress = lambda phrase: phrase.match_coarse_stress_pattern(pattern) target: Phrase = next(filter(match_stress, target_phrases)) We'll apply the same steps to find transcript phrases: # transcript says \"bell is glad a bottle\" # get all pronunciations for the phrase transcript_phrases = EnglishUtils.all_possible_phrases_for( [\"bell\", \"is\", \"glad\", \"a\", \"bottle\"] ) # in this case, there should be 4: assert len(transcript_phrases) == 4 Before we searched for a particular syllable-stress pattern. Let's ignore stress for a moment and simply look for a pattern of syllables. Imagine we're interested in phrases composed of 4 monosyllabic words followed by a disyllabic word. We can represent this pattern using X X X X XX where X denotes a syllable and whitespace represents a lexical boundary: # all of these phrases have 6 syllables with the structure \"X X X X XX\". # If you're unfamiliar with regular expressions, keep in mind that ... # ^ in the pattern below means \"starts with\" # $ in the pattern below denotes the \"end of sequence\" all(phrase.match_masked_syllables(pattern=\"^X X X X XX$\", mask=\"X\") for phrase in transcript_phrases) # for our comparisons, let's use the first one: transcript: Phrase = transcript_phrases[0] Alignment \uf0c1 Now that we have both a target and transcript , let's use ReAline to align the two phonological sequences: # let's calculate lexical boundary errors for the first one: aligner = ReAline() By default, ReAline expects to align IPA, so we'll first want to convert our ARPABet-based representations to IPA: target_phones = [ConverterUtils.arpabet_to_ipa(phone) for phone in target.phones] transcript_phones = [ConverterUtils.arpabet_to_ipa(phone) for phone in transcript.phones] alignment = aligner.align(target_phones, transcript_phones) alignment should have the following value in this case (NOTE: newlines added for better legibility): [ ('b', 'b'), ('\u00e6', '\u025b'), ('l', 'l'), ('\u028c', 'i'), ('n', '-'), ('s', 'z'), ('k', 'g'), ('l', 'l'), ('\u00e6', '\u00e6'), ('m', '-'), ('p', '-'), ('\u028c', '-'), ('n', '-'), ('d', 'd'), ('-', '\u028c'), ('b', 'b'), ('\u0252', '\u0252'), ('t', 't'), ('\u028c', '\u028c'), ('l', 'l') ] Error analysis \uf0c1 Now that we have an automatically aligned sequence, let's analyze the phonological and lexical boundary errors in our transcript . Phoneme errors \uf0c1 First, let's calculate phoneme errors: # phoneme_errors = aligner.phoneme_errors(alignment) Lexical boundary errors \uf0c1 Next, let's calculate lexical boundary errors (LBEs): target_stress = target.coarse_stress # should produce ['SW', 'S', 'W', 'SW'] transcript_masked_stress = transcript.mask_syllables(mask=\"X\") # should produce ['X', 'X', 'X', 'X', 'XX'] lbe_errors = calculate_lbes_from_stress(target_stress, transcript_masked_stress) # should produce [LexicalBoundaryError(error_type=LexicalBoundaryErrorType.INSERTION_WEAK, target_index=0, transcript_index=0)] Wrapping up \uf0c1 A script containing this same example can be found at examples/asu-use-case.py","title":"Aligning and error analysis"},{"location":"examples/asu-use-case/#introduction","text":"Let's take a look at how to use ReAline to align phonological sequences and then analyze errors in the style of Jiao et al. (2019) For this example, we'll need the following imports: from clu.phontools.lang.en import EnglishUtils from clu.phontools.struct import * from clu.phontools.pronouncing import ConverterUtils from clu.phontools.alignment.realine import * from clu.phontools.alignment.lbe import * We'll be aligning a target phrase with a transcript phrase. In our example, our target phrase will be ... balance clamp and bottle ... and our transcribed phrase will be ... bell is glad a bottle","title":"Introduction"},{"location":"examples/asu-use-case/#phrases-and-syllables","text":"clu-phontools makes it easy to find all possible attested pronunciations for a phrase via a pronouncing dictionary. In the case of English, we can use the CMU pronouncing dictionary : # prompt/target is \"balance clamp and bottle\" # get all pronunciations for the phrase # return a sequence of `clu.phontools.struct.Phrase` target_phrases = EnglishUtils.all_possible_phrases_for([\"balance\", \"clamp\", \"and\", \"bottle\"]) How many pronunciations did we find? In this case, there should be 2: assert len(target_phrases) == 2 Let's examine the stress patterns . Perhaps we only care about the distinction between strong (S) and weak (W) syllables: # let's examine the stress patterns... for phrase in target_phrases: print(phrase.coarse_stress) Perhaps we have a particular stress pattern we're interested in examining. For this example, we'll pretend we're interested in finding phrases with the stres pattern SW S W SW : # our stress pattern of interest pattern = \"SW S W SW\" # find the first Phrase that matches our pattern. # we'll use the first entry (stress pattern = [\"SW\", \"S\", \"W\", \"SW\"]) # as our target. match_stress = lambda phrase: phrase.match_coarse_stress_pattern(pattern) target: Phrase = next(filter(match_stress, target_phrases)) We'll apply the same steps to find transcript phrases: # transcript says \"bell is glad a bottle\" # get all pronunciations for the phrase transcript_phrases = EnglishUtils.all_possible_phrases_for( [\"bell\", \"is\", \"glad\", \"a\", \"bottle\"] ) # in this case, there should be 4: assert len(transcript_phrases) == 4 Before we searched for a particular syllable-stress pattern. Let's ignore stress for a moment and simply look for a pattern of syllables. Imagine we're interested in phrases composed of 4 monosyllabic words followed by a disyllabic word. We can represent this pattern using X X X X XX where X denotes a syllable and whitespace represents a lexical boundary: # all of these phrases have 6 syllables with the structure \"X X X X XX\". # If you're unfamiliar with regular expressions, keep in mind that ... # ^ in the pattern below means \"starts with\" # $ in the pattern below denotes the \"end of sequence\" all(phrase.match_masked_syllables(pattern=\"^X X X X XX$\", mask=\"X\") for phrase in transcript_phrases) # for our comparisons, let's use the first one: transcript: Phrase = transcript_phrases[0]","title":"Phrases and syllables"},{"location":"examples/asu-use-case/#alignment","text":"Now that we have both a target and transcript , let's use ReAline to align the two phonological sequences: # let's calculate lexical boundary errors for the first one: aligner = ReAline() By default, ReAline expects to align IPA, so we'll first want to convert our ARPABet-based representations to IPA: target_phones = [ConverterUtils.arpabet_to_ipa(phone) for phone in target.phones] transcript_phones = [ConverterUtils.arpabet_to_ipa(phone) for phone in transcript.phones] alignment = aligner.align(target_phones, transcript_phones) alignment should have the following value in this case (NOTE: newlines added for better legibility): [ ('b', 'b'), ('\u00e6', '\u025b'), ('l', 'l'), ('\u028c', 'i'), ('n', '-'), ('s', 'z'), ('k', 'g'), ('l', 'l'), ('\u00e6', '\u00e6'), ('m', '-'), ('p', '-'), ('\u028c', '-'), ('n', '-'), ('d', 'd'), ('-', '\u028c'), ('b', 'b'), ('\u0252', '\u0252'), ('t', 't'), ('\u028c', '\u028c'), ('l', 'l') ]","title":"Alignment"},{"location":"examples/asu-use-case/#error-analysis","text":"Now that we have an automatically aligned sequence, let's analyze the phonological and lexical boundary errors in our transcript .","title":"Error analysis"},{"location":"examples/asu-use-case/#phoneme-errors","text":"First, let's calculate phoneme errors: # phoneme_errors = aligner.phoneme_errors(alignment)","title":"Phoneme errors"},{"location":"examples/asu-use-case/#lexical-boundary-errors","text":"Next, let's calculate lexical boundary errors (LBEs): target_stress = target.coarse_stress # should produce ['SW', 'S', 'W', 'SW'] transcript_masked_stress = transcript.mask_syllables(mask=\"X\") # should produce ['X', 'X', 'X', 'X', 'XX'] lbe_errors = calculate_lbes_from_stress(target_stress, transcript_masked_stress) # should produce [LexicalBoundaryError(error_type=LexicalBoundaryErrorType.INSERTION_WEAK, target_index=0, transcript_index=0)]","title":"Lexical boundary errors"},{"location":"examples/asu-use-case/#wrapping-up","text":"A script containing this same example can be found at examples/asu-use-case.py","title":"Wrapping up"},{"location":"examples/misc/","text":"Alignment with ReAline (simple) \uf0c1 coming soon Aligning and analyzing errors (end-to-end) \uf0c1 See this page for an end-to-end example of features. REST API \uf0c1 Prefer to interact with the library from another language? See this page for an example of how to use our REST API.","title":"Overview"},{"location":"examples/misc/#alignment-with-realine-simple","text":"coming soon","title":"Alignment with ReAline (simple)"},{"location":"examples/misc/#aligning-and-analyzing-errors-end-to-end","text":"See this page for an end-to-end example of features.","title":"Aligning and analyzing errors (end-to-end)"},{"location":"examples/misc/#rest-api","text":"Prefer to interact with the library from another language? See this page for an example of how to use our REST API.","title":"REST API"},{"location":"examples/rest-api/","text":"docker run -i -p 8000:8000 \"parsertongue/clu-phontools:latest\" clu-phontools-rest-api To view the interactive OpenAPI docs for the REST API, open your browser to localhost:8000/docs","title":"REST API"}]}